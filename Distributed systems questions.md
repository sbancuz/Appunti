---
tags:
  - distributed_systems
---
### Describe the REST architectural style

The REST style is s way to build a client server application that communicates under HTTP/HTTPS via JSON messages. This is because REST only offers four methods for communication: PUT, POST, GET, DELETE; thus there isn't enough methods to build an entire application. The solution to this problem is to encode the signature and arguments of a function is a JSON message and send that through one of the four methods listed before. The other main point of REST is that only the client should hold the state of the connection, thus the server shall have no such concept. In reality a pure REST application is hard to implement and wouldn't really meet the needs of the users, for this reason usually the server will hold some information of the client in persistent storage like a database.

All the responses that the client receives can be specified to be cached.
### Describe name resolution in general and focus on the various approaches you know to resolve flat names.

Names are used to refer to entities in a system, there are two types of names: human friendly -- usually represented as strings -- and machine friendly - -represented as ips.  Name resolution stands for the process of converting a human friendly name to the actual address of the machine. Name resolution can happen in three main methods: flat naming, structured naming and attribute based naming.

In flat naming every machine has it's own name, usually without any meaning or structure to it represented with a string. There are various versions for resolution of flat names, for simple solutions like home networks we can just broadcast the network or in some cases even use multicast to find the device. To handle mobile devices we can use forwarding pointers that transfer the reference of the device between routers when in motion. There are also home based approaches that works by having a "home server" and when a client needs to find another node in the network, it can just contact this server that know where everybody is, the problem with this approach is that the server location is fixed, so requests may have to travel a lot even if the two devices are not very far from one another. An extension of a home based approach is to use a dth that divides the network into various subnetworks and knows the address of everybody in it's own network, if a client needs to communicate with someone outside the network, the request will navigate between the various dth s until it finds the desired network and then it gets to the receiver. As a last technique we have hierarchical naming, with this approach the names have some structure and are organized as a tree like a directory in a file system, and every non leaf node knows of every children node, this has obvious bad implications, in fact the top level root node has information about every node in the network.
### Describe leader election protocols and compare them in terms of assumptions and number of messages required to end the election

In a distributed system leader election can happen in two ways: bully election and ring based. Both of these protocol require a reliable connection and a unique id that distinguishes them from every other node. Also we have to treat the system as if it was a synchronous one, so recognizing that someone has crashed needs to be possible.

The bully election protocol works by trying to elect the highest id node in the network as a leader, this happens in a few steps: first a node has to notice that a node is unresponsive, that the same node will try to contact every other node that it knows has higher id that them and waits for a response. If it receives no response then it will assume that it's the new leader of the network and send a new message notifying every other node of this change. 
In contrast the ring based protocol it arranges the nodes in a logical loop and still tries to elect a new leader with highest id. When a process notices that the leader is non respondent, it will send a message containing its id to the next node in the chain, if a node doesn't respond then it will try the next one and so on, then the receiver will add it's own id to the message and pass it along. If a node receives a message containing it's own id, then it will select the highest id node and pass the information along to all the nodes.
### Consider the MapReduce programming model and the execution framework:

1) Explain the programming primitives that the model offers.
	The model offers a two primitives: a map function that represents a pure function that applies a functor to some data, and then it returns the result, and the reduce that takes as input the list of result of the map computation and applies a "reducing" function to it then returning only a single result.
	
2) Exemplify these programming primitives using a word/count application that takes in input some documents and outputs the number of occurrences of each word appearing in the documents.
	In this kind of system we can view the word counting function as the map function that takes in input a file and then it will return a map that connects every word with its number of occurrences. Then we can view the reduce as the operation that takes in all the various maps, given as a result of every computation of every file, and it will combine them all into one
	
3) Explain how the execution framework handles data parallelism, data locality, fault tolerance and stragglers.
	Each computation can be done in parallel since the function that both the map and the reduce use are pure, this means that the result of their computation depends only on their input. This property makes the system massively parallelizable. But when having such a parallel application we have to think about the data locality, because transfer speeds are usually much slower than any computation, this imposes a limit on how distant data can be from one another, usually data is contained in the same data center or even in the same rack. To handle all this processes we use a node that act as a master that checks if some nodes are slower or even crash, if they are slower than others they are called stragglers and they will be given less amount of work, this is because if they had the same amount of work as some other node the whole computation will be limited just by the speed of this node. The objective of the master is also to find the crashes in the system, in one is detected then the master will ask to redo all the work to some other node, if by any chance the node that has been considered crashes responds with a result, the message will be ignored.
### Describe the following three approaches for search and lookup in a p2p network. Compare them in terms of state maintained at each node, search expressivity, search scope, guarantees of lookup success, resilience to network dynamicity (joins and leaves of nodes)

-  Centralized table (e.g. Napster)
	When there is a centralized table there is a node in the network that holds the location of every other node in the network and what each node is posting. Each node will only hold information regarding the location of the central table and what resources it makes available. A node can easily search for a resource in the entire network just by asking the central directory if it holds the reference to a node that provides it, so there are no guarantees of success. New nodes to subscribe to a network, a new node just has to contact the central server that will respond with the list of the documents that the network offers.

- Flooding (e.g. Gnutella)
	In query flooding there is no concept of a centralized or semi centralized resource that holds information about the system, to find a resource you have to ask to every node you can reach and if they don't have it, they will forward the request to each of their peers. This method is extremely wasteful and does not guarantee anything about whether or not a resource is available on the network, to find out you have to ask everyone. This approach is also very sensible of network dynamicity because if a node leaves it can divide the network in two separate network without no one noticing, though this eventuality is quite unlikely in a big network since when a node tries to connect, it has to inform every node on the network and the most free one will establish a connection between them. The probability of accepting a connection is inversely proportional to the number of active connections.
 
- Distributed Hash Table (DHT, e.g. Chord)
	Chord is a middle ground with the centralized hash table approach and the query flooding one. There isn't only a central node that holds the references of all nodes in the network, but there are multiple tables that divide the network based on the hash of the resource they offer. Each table holds the position of every other table in the network. When entering this network a client just needs to contact a node that will lead it to the right hash table to register to the network. When searching one needs to contact a dth based on the computed hash of the search and ask it if it holds the resource, if the resource isn't available then we are sure that is not available in the entire system.
### Describe the various mobile code paradigms and the type of technologies that support them? Which paradigm is the most complex to implement? Why?

There are four types of mobile code paradigms: client server -- where the client makes a request to the server and then the server will respond with some kind of result, all the computation will happen in the server and the client doesn't know how the result is produced -- this type architecture is used in most web application and api; remote evaluation -- where the client tells the server what operation it should execute then the server will reply with the result -- that is used to offload computation like in a scientific environment; code on demand -- where the client will ask the server how it should handle a computation, the server will respond with the actual code -- and is mostly used by web browsers that download javascript bundles that will run on the client; and lastly mobile agent -- a client will create a connection with a server and use it's resources as if it was using its own, all the result will remain on the server; The more a system is mobile, the more complex it is to implement, this means that the mobile agent is the most complex to maintain of them all, preceded by remote evaluation, code on demand and client server in order.
### Describe the difference between flat naming system implemented using hierarchy of servers and structured naming implemented using similar hierarchy or servers. Compare the two solution and explain why the latter is more efficient then the former.

Both hierarchical flat naming and structured naming compose the network in a tree-like structure, dividing the network between nodes. The main difference between them is the name resolution procedure, the former has to potentially ask every root node if it has the desired destination, and if it hasn't, then it has to ask their root and so on, so it's a bottom up approach where every root node has to know every node in it's subtree. The latter is a top down approach that in which, a root node may not know where the exact destination is, but it knows where to ask for the information, this means that the root only has to know about its leaves and the lookup speed is consistent because it has to ask at most h -- height of the tree -- nodes to find the destination.
### Consider client centric consistency models. In which situation are they relevant? Define the 4 models presented in class and discuss how can they be implemented

Client centric consistency models are relevant when a distributed system wants to serve multiple clients that are very far apart geographically; in such cases the main bottleneck will become the transfer speed of the network, which is the speed of light. To resolve this latency issue we can replicate the systems' data in various servers and keep them in sync with each other, this is for example how cdn work. To implement such systems we can use one of these different models:

Sequential consistency $\to$ All operations by all processes must be executed as if they were executed in some sequential order and each operation must appear in the same sequence as specified by its program. This is not a good approach since it basically replicates a synchronous system, thus including massive latency and as such, the system wouldn't be highly available. It can be implemented either with a single server that acts as a leader that dictates the single source of truth, thus all the write operations must be sent to the leader, or in a leaderless context with a quorum that votes on the changes made by the system.

Linearizable consistency $\to$ All write operations should be considered as immediately visible to all the other replicas. This system uses vector clocks to maintain timestamps of the state of the system. Only the leader can commit new information to the system and when it does, it must lock all replicas to perform an atomic update.  This kind of system is hard to maintain in the presence of failures.

Causal consistency $\to$ All write operations that may be causally related must be seen by all processes in the same order based on the notion of Lamport's happens before relationship. This type of system can be implemented with a multi leader system that keeps timestamps of each write operation and commits to persistent storage only if all possible causes of a write are processed.

FIFO consistency $\to$ Writes done by a single process are seen by all others in the order in which they were issued; writes from difference processes may be seen in a different order at different machines. This can easily be implemented with multi leader protocol by committing changes only if all other changes from the sender process were applied.
### With reference to big data processing platforms: explain the difference between pipelined and scheduled execution and discuss how the two execution models influence the parallelism, load balancing and elasticity

In big data platforms the work is usually divided between multiple processes, in order to handle the work we usually use the map reduce pattern. With this pattern data can be distributed to a lot of nodes in the network to be processed independently from one another. In fact, both of the map and reduce operation must be pure functions. To divide the work into multiple processes, a scheduler is used and it divides the work in chunks and sends it to a process to be processed. This kind of scheduling only performs one type of operation in the mapping stage, so it can create a lot of redundant work with the reduce operation and also a lot of redundant traffic. To resolve this problem we can apply a pipelining approach to all the operations, thus using the intermediate results to perform multiple operations before reducing the result. Both of these approaches are massively parallelizable, with an advantage to the pipelined execution for having way less network request, thus higher throughput. The problem with a pipelined approach arises when dealing with load balancing, and as a consequence elasticity. This is because since all operation are done by a single process, if that very process is slow, then it will still have to do all the work and that may impact the performance of the system. This problem doesn't exist with a scheduled approach because, since the scheduler asks only to process one operation at a time, the whole computation takes a lot less and if a client is identified as slow, then we can just redirect the computation to other processes.
### Describe publish/subscribe in detail discussing the various alternatives for the subscription language, then describe and compare the various approaches to implement a distributed (acyclic) dispatcher

There are two types of languages to use when subscribing to a publish subscribe network: subject based and content based. The former describe the content by assigning it a subject from a predetermined set of subjects and all the clients that subscribe to that subject will receive a notification. The latter describes the content, dividing in key value pairs the type of content of the resource and sending all interested clients a notification. We can implement such system in three different way in a acyclic dispatcher: 

Message forwarding $\to$ When a broker receives a message it forwards it to the interested clients that are connected to it, and then it forwards it to all other brokers in the network. There are no difference in this implementation between content based and subject based

Subscription forwarding $\to$ All the brokers know the shortest path to find all the interested clients, when it receives a message about a subject, a broker forwards it using that information to the next broker, or if available, to the interested client. Both approaches are possible with subscription forwarding, but since content based will cause a lot of subscriptions, this approach doesn't work well since it would be faster to just broadcast the message.

Hierarchical forwarding $\to$ All network assumes a overlay tree, all of the subscription flow towards the nodes in the tree only if they are interested in the message.
### Describe and compare the various approaches you know to implement flat naming

In flat naming, the clients are represented by a human readable string and are almost always meaningless. There are five main approaches to achieve name resolution:
Broadcast/Multicast $\to$ Ask every /some node in the network if it's the desired node. This is only good for small networks, like LAN
Forwarding pointer $\to$ This approach is used with mobile clients that may switch access point during the connection, in this case the connection is passed between servers seamlessly from the client
Home based approach $\to$ There exists a known home server that every node queries when it wants to find someone else in the network, this also works for larger networks, but still has problems with latency due to geographic distance between the home and the clients.
DHT $\to$ There is a network tree overlayed to all nodes in the network, when a clients wants to find another it asks the information to the relevant hash table. 
Hierarchical flat naming $\to$ This approach is the exception to the "meaningless" string name, in 