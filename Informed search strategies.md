---
tags:
  - artificial_intelligence
---
Unlike the *normal* search algorithms, informed search strategies use domain specific hints about the location of goals. These hints come in the form of a **heuristic function** denoted $h(n)$.

>[!example]
>In route finding problems, we can estimate the distance from the current state to a goal by computing the straight line distance on the map between the two points.
#### Greedy best-first search

This is a form of best-first search that expands first the node with the lowest $h(n)$ value on the grounds that is likely to lead to a solution quickly. On each iteration it tries to get as close to a goal as it can. Even though it's fast being $O(|V|)$ for the time complexity, it does not guarantee the best solution to the problem. With a good heuristic function , however, the time complexity can be reduced substantially, and on certain problems reaching $O(bm)$
#### A star

The most common informed search algorithm is A start search, a variation of best first search that uses 
$$
f(n) = g(n) + h(n)
$$
where $g(n)$ is the path cost from the initial state to node $n$, and $h(n)$ is the **estimated** cost of the shortest path from $n$ to a goal state. This algorithm is complete, but whether A star is cost optimal or not it depends on certain properties of the heuristic:
- Admissibility -> it never overestimates the cost to reach a goal
- Consistency -> every node $n$, every successor $n'$ generated by an action $a$ has $h(n)\leq c(n,a,n') + h(n')$

A useful way to visualize a search is to draw **contours** in the state space, just like in a topographic map.

![[contour.png]]

It should be clear that as you extend a path, the $g$ cost are **monotonic** -- the path cost always increases as you go along a path, because action costs are always positive. Therefore you get concentric contour lines that don't cross each other. The problem is that is not obvious whether the $f= g + h$ cost will monotonically increase, in fact this property holds only if $h(n) \leq c(n,a,n') + h(n')$.

>[!note]
>A path might contribute several nodes in a row with the same $g + h$ score. This will happen if whenever the decrease in $h$ is exactly equal to the action cost just taken.

If $C^{*}$ is the cost of the optimal solution path, then we can say the following:
- $A^{*}$ expands all nodes that can be reached from the initial state on a path where every node has $f(n) < C^{*}$
- $A^{*}$ might expand some of the nodes right on the goal contour where $f(n) = C^{*}$
- $A^{*}$ doesn't expand any nodes with $f(n) > C^{*}$

With this we can say that $A^{*}$ with a consistent heuristic is **optimally efficient** in the sense that any algorithm that extends search paths from the initial state must expand all nodes that are surely expanded by $A^{*}$. 

$A^{*}$ is very efficient because it **prunes** away search tree nodes that are not necessary for finding an optimal solution.

To reduce the memory required for $A^{*}$ by searching every time to an augmenting depth like the [[Uninformed search strategies#Iterative deepening search]].
#### Satisficing search

If we are willing to accept solutions that are suboptimal, but "good enough" -- what we call **satisficing solutions** -- we need to allow $A^{*}$ to use inadmissible heuristic.

>[!example]
>![[weighted a star.png]]

We can call the approach of having weights for every node the **weighted $A^{*}$ search** where we weight the heuristic value more heavily, giving us the evaluation function $f(n) = g(n) + W \times h(n)$ for $W > 1$.

>[!note]
>This could be seen as a greedy search algorithm, because it's not focused on finding a optimal solution

